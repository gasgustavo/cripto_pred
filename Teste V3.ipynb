{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8ec57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy as copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, GRU\n",
    "from tensorflow.keras.layers import SimpleRNN\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import RepeatVector\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "path = 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4c14aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(file_path):\n",
    "    \n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "def feature_engineering(df_raw, features, estrategy='simple'):\n",
    "    \n",
    "    if estrategy == '':\n",
    "        pass\n",
    "    else:\n",
    "        df = df_raw[features + ['timestamp']]\n",
    "        df = df.set_index('timestamp', drop=True)\n",
    "        \n",
    "    return df\n",
    "\n",
    "def format_data(data_list, labels, janela_de_tempo, janela_de_predicao):\n",
    "    \n",
    "    n_features = len(data_list)\n",
    "    n_dataset = len(data_list[0])\n",
    "    hist_list = [[] for _ in range(n_features)]\n",
    "    target = []\n",
    "\n",
    "    for i in range(n_dataset-(janela_de_tempo + janela_de_predicao)):\n",
    "        for data_index, data in enumerate(data_list):\n",
    "            x = data[i:i+janela_de_tempo]\n",
    "            hist_list[data_index].append(x)\n",
    "        y = labels[i+janela_de_tempo:i+janela_de_tempo+janela_de_predicao]\n",
    "\n",
    "        target.append(y)\n",
    "        \n",
    "    #convertendo de lista para array\n",
    "    hist_list = [np.array(hist) for hist in hist_list]\n",
    "    target = np.array(target)\n",
    "    \n",
    "    return hist_list, target\n",
    "\n",
    "def split_train_test(hist_list, target):\n",
    "    \"\"\"\n",
    "        60% train\n",
    "        20% test\n",
    "        20% validation\n",
    "    \"\"\"\n",
    "    \n",
    "    X_train_list, X_test_list, X_val_list  = [], [], []\n",
    "    \n",
    "    for hist in hist_list: \n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(hist, target, test_size=0.2, random_state=1)\n",
    "\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1) # 0.25 x 0.8 = 0.2\n",
    "        \n",
    "        X_train_list.append(X_train)\n",
    "        X_test_list.append(X_test)\n",
    "        X_val_list.append(X_val)\n",
    "        \n",
    "    return X_train_list, X_test_list, X_val_list , y_train, y_test, y_val\n",
    "\n",
    "def normalize_data(X_train_list, X_test_list, X_val_list, y_train, y_test, y_val, janela_de_tempo):\n",
    "    ##Normalizando...\n",
    "    \n",
    "    for index, (X_train, X_test, X_val) in enumerate(zip(X_train_list, X_test_list, X_val_list)):\n",
    "        sc = MinMaxScaler()\n",
    "        sc.fit(X_train)\n",
    "        X_train = sc.transform(X_train)\n",
    "        X_test = sc.transform(X_test)\n",
    "        X_test = sc.transform(X_val)\n",
    "\n",
    "        X_train = X_train.reshape((len(X_train), janela_de_tempo, 1))\n",
    "        X_test = X_test.reshape((len(X_test), janela_de_tempo, 1))\n",
    "        X_val = X_test.reshape((len(X_val), janela_de_tempo, 1))\n",
    "        \n",
    "        X_train_list[index] = X_train\n",
    "        X_test_list[index] = X_test\n",
    "        X_val_list[index] = X_val\n",
    "        \n",
    "    X_train = np.dstack(X_train_list)\n",
    "    X_test = np.dstack(X_test_list)\n",
    "    X_val = np.dstack(X_val_list)\n",
    "\n",
    "    sc.fit(y_train)\n",
    "    y_train = sc.transform(y_train)\n",
    "    y_test = sc.transform(y_test)\n",
    "    y_val = sc.transform(y_val)\n",
    "    \n",
    "    return X_train, X_test, X_test, y_train, y_test, y_val, sc\n",
    "\n",
    "\n",
    "def create_model(janela_de_tempo, features, estrategy='simple'):\n",
    "    \n",
    "    model = None\n",
    "    \n",
    "    if estrategy=='simple' :\n",
    "        model = tf.keras.Sequential()\n",
    "\n",
    "        #encoder\n",
    "        model.add(LSTM(25, input_shape=(janela_de_tempo,len(features))))\n",
    "        model.add(Dropout(0.10))\n",
    "\n",
    "        #Gate do decoder\n",
    "        model.add(RepeatVector(y_train.shape[1]))\n",
    "\n",
    "        #decoder\n",
    "        model.add(LSTM(25, return_sequences=True))\n",
    "        model.add(TimeDistributed(Dense(10)))\n",
    "        model.add(Dense(1))\n",
    "\n",
    "        print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138fa153",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_list = []\n",
    "\n",
    "list_files = os.listdir(path)\n",
    "#list_files = ['BCHUSDT-5m-data.csv', \"ETCUSDT-5m-data.csv\"]\n",
    "print(f'Existem {len(list_files)} arquivos')\n",
    "\n",
    "\n",
    "parameters_list = [\n",
    "#     dict(\n",
    "#         estrategy = 'simple',\n",
    "#         optimizer='adam',\n",
    "#         loss='binary_crossentropy',\n",
    "#         janela_de_tempo = 60,   # Quantidade de slots utilizados pra predicao\n",
    "#         janela_de_predicao = 10, # Quanditade de slots pra frente que serao preditos \n",
    "#         epochs = 20,\n",
    "#         batch_size = 32\n",
    "#         features=['close']\n",
    "#     ),\n",
    "    dict(\n",
    "        estrategy = 'simple',\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        janela_de_tempo = 60,   # Quantidade de slots utilizados pra predicao\n",
    "        janela_de_predicao = 10, # Quanditade de slots pra frente que serao preditos \n",
    "        epochs = 20,\n",
    "        batch_size = 32,\n",
    "        features = [\"high\", \"low\", \"close\"]\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a43127b",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = list_files[0]\n",
    "parameter = parameters_list[0]\n",
    "file, parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf64a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "estrategy = parameter['estrategy']\n",
    "optimizer=parameter['optimizer']\n",
    "loss=parameter['loss']\n",
    "janela_de_tempo =parameter['janela_de_tempo']\n",
    "janela_de_predicao =parameter['janela_de_predicao']\n",
    "epochs =parameter['epochs']\n",
    "batch_size =parameter['batch_size']\n",
    "features =parameter['features']\n",
    "\n",
    "file_path = os.path.join(path,file)\n",
    "df_raw = load_file(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0401b2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = feature_engineering(\n",
    "    df_raw, \n",
    "    features,\n",
    "    estrategy=estrategy\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fa4647",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, 'rotulo'] = df['close']\n",
    "data_list = [df.loc[:, feature] for feature in features]\n",
    "labels = df['rotulo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1edba13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef1b99f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c637a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_list, target = format_data(data_list, labels, janela_de_tempo, janela_de_predicao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb76add9",
   "metadata": {},
   "outputs": [],
   "source": [
    "[len(hist) for hist in hist_list], len(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a80e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_list, target = format_data(data_list, labels, janela_de_tempo, janela_de_predicao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4876223",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_list, X_test_list, X_val_list , y_train, y_test, y_val = split_train_test(hist_list, target)\n",
    "X_train, X_test, X_val, y_train, y_test, y_val, sc = normalize_data(\n",
    "    X_train_list, X_test_list, X_val_list, y_train, y_test, y_val, janela_de_tempo\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f3e8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(janela_de_tempo, features, estrategy='simple')\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=epochs, validation_data=(X_val, y_val),  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cb8190",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1051705d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Existem {len(list_files)} arquivos')\n",
    "\n",
    "for file in list_files:\n",
    "    \n",
    "    for index_parameter, parameter in enumerate(parameters_list):\n",
    "        print(\"----------------------------------------------------------\")\n",
    "        print(f'EXPERIMENTANDO: {file} ---- estrategia {index_parameter}')\n",
    "        print(parameter)\n",
    "        dict_log = copy(parameter)\n",
    "        dict_log['index_parameter'] = index_parameter\n",
    "        dict_log['file'] = file\n",
    "        \n",
    "        # Parametros do experimento\n",
    "        estrategy = parameter['estrategy']\n",
    "        optimizer=parameter['optimizer']\n",
    "        loss=parameter['loss']\n",
    "        janela_de_tempo =parameter['janela_de_tempo']\n",
    "        janela_de_predicao =parameter['janela_de_predicao']\n",
    "        epochs =parameter['epochs']\n",
    "        batch_size =parameter['batch_size']\n",
    "        features =parameter['features']\n",
    "\n",
    "        file_path = os.path.join(path,file)\n",
    "        df_raw = load_file(file_path)\n",
    "        #del df_raw\n",
    "        df = feature_engineering(\n",
    "            df_raw,\n",
    "            features,\n",
    "            estrategy=estrategy\n",
    "        )\n",
    "\n",
    "\n",
    "        df.loc[:, 'rotulo'] = df['close']\n",
    "        data_list = [df.loc[:, feature] for feature in features]\n",
    "        labels = df['rotulo']\n",
    "\n",
    "        hist_list, target = format_data(data_list, labels, janela_de_tempo, janela_de_predicao)\n",
    "        dict_log['len_database'] = len(data_list[0])\n",
    "        \n",
    "        X_train_list, X_test_list, X_val_list , y_train, y_test, y_val = split_train_test(hist_list, target)\n",
    "        X_train, X_test, X_test, y_train, y_test, y_val, sc = normalize_data(\n",
    "            X_train_list, X_test_list, X_val_list, y_train, y_test, y_val, janela_de_tempo\n",
    "        )\n",
    "\n",
    "        model = create_model(janela_de_tempo, features, estrategy='simple')\n",
    "        model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "        history = model.fit(X_train, y_train, epochs=epochs, validation_data=(X_val, y_val),  batch_size=batch_size)\n",
    "\n",
    "        pred = model.predict(X_test)\n",
    "\n",
    "        mae_val = mean_absolute_error([i[0] for i in y_test], [i[0] for i in pred])\n",
    "        dict_log['history'] = history.history\n",
    "        dict_log['mae_val'] = mae_val\n",
    "        \n",
    "        log_list.append(dict_log)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86dbd4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "now_ts  = int(datetime.now().timestamp())\n",
    "pd.DataFrame(log_list).to_csv(f'results/resultados-v2-{now_ts}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2a002a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(log_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a36d0ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
